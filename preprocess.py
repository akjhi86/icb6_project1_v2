"""
ì¹´í˜ ì…ì§€ ë¶„ì„ ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
4ê°œ CSV íŒŒì¼ì„ ì½ì–´ ëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš©í•  JSON ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import pandas as pd
import json
import os
import warnings
warnings.filterwarnings('ignore')

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_DIR = os.path.join(os.path.dirname(__file__), 'data')
OUTPUT_DIR = os.path.dirname(__file__)

BRANDS = ['ë”ë²¤í‹°', 'ë§¤ë¨¸ë“œì»¤í”¼', 'ë©”ê°€ì»¤í”¼', 'ë¹½ë‹¤ë°©', 'ì»´í¬ì¦ˆì»¤í”¼']
BRAND_COLS = [f'count_{b}' for b in BRANDS]

# ë¸Œëœë“œë³„ ìƒ‰ìƒ
BRAND_COLORS = {
    'ë”ë²¤í‹°':    '#FF6B6B',
    'ë§¤ë¨¸ë“œì»¤í”¼': '#4ECDC4',
    'ë©”ê°€ì»¤í”¼':  '#FFE66D',
    'ë¹½ë‹¤ë°©':    '#A8E6CF',
    'ì»´í¬ì¦ˆì»¤í”¼': '#C3A6FF',
}

print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. brand_analysis_master.csv ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("  [1/4] brand_analysis_master.csv ë¡œë”©...")
df_brand = pd.read_csv(
    os.path.join(DATA_DIR, 'brand_analysis_master.csv'),
    encoding='utf-8-sig'
)

# í–‰ì •ë™ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ í†µì¼
df_brand['í–‰ì •ë™ì½”ë“œ'] = df_brand['í–‰ì •ë™ì½”ë“œ'].astype(str).str.strip()

# ìˆ«ìí˜• ë³€í™˜
brand_cols_numeric = BRAND_COLS + ['total_workers', 'female_workers',
    'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—¬ì„±_ë§¤ì¶œ_ê¸ˆì•¡',
    'ì—°ë ¹ëŒ€_10_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_20_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_30_ë§¤ì¶œ_ê¸ˆì•¡',
    'ì—°ë ¹ëŒ€_40_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_50_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ë§¤ì¶œ_ê¸ˆì•¡']
for col in brand_cols_numeric:
    if col in df_brand.columns:
        df_brand[col] = pd.to_numeric(df_brand[col], errors='coerce')

# í–‰ì •ë™ì½”ë“œë³„ ì§‘ê³„ (ë¸Œëœë“œ ì¹´ìš´íŠ¸ëŠ” max, ë§¤ì¶œì€ sum)
agg_dict = {}
for col in BRAND_COLS:
    if col in df_brand.columns:
        agg_dict[col] = 'max'
for col in ['total_workers', 'female_workers']:
    if col in df_brand.columns:
        agg_dict[col] = 'max'
for col in ['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—¬ì„±_ë§¤ì¶œ_ê¸ˆì•¡',
            'ì—°ë ¹ëŒ€_10_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_20_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_30_ë§¤ì¶œ_ê¸ˆì•¡',
            'ì—°ë ¹ëŒ€_40_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_50_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ë§¤ì¶œ_ê¸ˆì•¡']:
    if col in df_brand.columns:
        agg_dict[col] = 'sum'

df_brand_agg = df_brand.groupby(['í–‰ì •ë™ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ_ëª…'], as_index=False).agg(agg_dict)
print(f"     â†’ {len(df_brand_agg)}ê°œ í–‰ì •ë™")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. seoul_dong_attractiveness.csv ë¡œë“œ (ì—…ë°ì´íŠ¸ëœ ì»¬ëŸ¼ëª…)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("  [2/4] seoul_dong_attractiveness.csv ë¡œë”©...")
df_attr = pd.read_csv(
    os.path.join(DATA_DIR, 'seoul_dong_attractiveness.csv'),
    encoding='utf-8-sig'
)
# ì»¬ëŸ¼ëª… í™•ì¸ í›„ í–‰ì •ë™_ì½”ë“œ ì»¬ëŸ¼ ì‚¬ìš© (10ìë¦¬)
print(f"     ì»¬ëŸ¼: {list(df_attr.columns)}")
df_attr['í–‰ì •ë™_ì½”ë“œ'] = df_attr['í–‰ì •ë™_ì½”ë“œ'].astype(str).str.strip()
print(f"     â†’ {len(df_attr)}ê°œ í–‰ì •ë™")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. seoul_caffee_data_with_coords.csv ë¡œë“œ (ì¢Œí‘œ ë°ì´í„°)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("  [3/4] seoul_caffee_data_with_coords.csv ë¡œë”© (ëŒ€ìš©ëŸ‰)...")
df_coords = pd.read_csv(
    os.path.join(DATA_DIR, 'seoul_caffee_data_with_coords.csv'),
    encoding='utf-8-sig',
    usecols=lambda c: c in ['í–‰ì •ë™ì½”ë“œ', 'ì‚¬ì—…ì¥ëª…', 'ë¸Œëœë“œ', 'latitude', 'longitude']
)
df_coords['í–‰ì •ë™ì½”ë“œ'] = df_coords['í–‰ì •ë™ì½”ë“œ'].astype(str).str.strip()
df_coords['latitude'] = pd.to_numeric(df_coords['latitude'], errors='coerce')
df_coords['longitude'] = pd.to_numeric(df_coords['longitude'], errors='coerce')

# ì €ê°€ ë¸Œëœë“œë§Œ í•„í„°ë§
df_target = df_coords[df_coords['ë¸Œëœë“œ'].isin(BRANDS)].dropna(subset=['latitude', 'longitude'])
print(f"     â†’ ì „ì²´ ì¹´í˜: {len(df_coords):,}ê°œ, ì €ê°€ ë¸Œëœë“œ: {len(df_target):,}ê°œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. seoul_caffee_data_with_brand.csv ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("  [4/4] seoul_caffee_data_with_brand.csv ë¡œë”© (ëŒ€ìš©ëŸ‰)...")
df_brand_raw = pd.read_csv(
    os.path.join(DATA_DIR, 'seoul_caffee_data_with_brand.csv'),
    encoding='utf-8-sig',
    usecols=lambda c: c in ['í–‰ì •ë™ì½”ë“œ', 'ì‚¬ì—…ì¥ëª…', 'ë¸Œëœë“œ']
)
df_brand_raw['í–‰ì •ë™ì½”ë“œ'] = df_brand_raw['í–‰ì •ë™ì½”ë“œ'].astype(str).str.strip()
print(f"     â†’ {len(df_brand_raw):,}ê°œ ì¹´í˜")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë³‘í•© (í–‰ì •ë™ì½”ë“œ ì§ì ‘ ë§¤ì¹­)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ”— ë°ì´í„° ë³‘í•© ì¤‘...")

df_merged = df_brand_agg.merge(
    df_attr.rename(columns={'í–‰ì •ë™_ì½”ë“œ': 'í–‰ì •ë™ì½”ë“œ'}),
    on='í–‰ì •ë™ì½”ë“œ',
    how='left'
)
matched = df_merged['ë§¤ë ¥ë„ì ìˆ˜'].notna().sum()
print(f"  ë³‘í•© ê²°ê³¼: {len(df_merged)}ê°œ í–‰ì •ë™, ë§¤ë ¥ë„ ë§¤ì¹­: {matched}ê°œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON ë°ì´í„° ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“Š JSON ë°ì´í„° ìƒì„± ì¤‘...")

# ì»¬ëŸ¼ëª… ë§¤í•‘ (í•œêµ­ì–´ â†’ ì˜ì–´ í‚¤)
COL_MAP = {
    'ì´_ë§¤ì¶œ':       'total_sales',
    'ì´_ì§ì›ìˆ˜':     'total_workers_attr',
    'ì¹´í˜_ìˆ˜':       'cafe_count',
    'mÂ²ë‹¹_í‰ê· _ê°€ê²©': 'avg_price_per_m2',
    'ìˆ˜ìš”ì ìˆ˜':      'demand_score',
    'ê²½ìŸì ìˆ˜':      'competition_score',
    'ë¹„ìš©ì ìˆ˜':      'cost_score',
    'ë§¤ë ¥ë„ì ìˆ˜':    'attractiveness_score',
}

def safe_float(val):
    try:
        v = float(val)
        return None if pd.isna(v) else v
    except:
        return None

def safe_int(val):
    try:
        v = float(val)
        return 0 if pd.isna(v) else int(v)
    except:
        return 0

# 1) í–‰ì •ë™ë³„ ë¸Œëœë“œ í˜„í™© + ë§¤ë ¥ë„ ì ìˆ˜
dong_data = []
for _, row in df_merged.iterrows():
    brand_counts = {}
    total_brand = 0
    for brand, col in zip(BRANDS, BRAND_COLS):
        cnt = safe_int(row.get(col, 0))
        brand_counts[brand] = cnt
        total_brand += cnt

    dong_data.append({
        'dong_code': str(row['í–‰ì •ë™ì½”ë“œ']),
        'dong_name': str(row['í–‰ì •ë™_ì½”ë“œ_ëª…']),
        'brands': brand_counts,
        'total_brand_count': total_brand,
        'total_workers': safe_int(row.get('total_workers')),
        'female_workers': safe_int(row.get('female_workers')),
        'monthly_sales': safe_float(row.get('ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'male_sales': safe_float(row.get('ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'female_sales': safe_float(row.get('ì—¬ì„±_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_10': safe_float(row.get('ì—°ë ¹ëŒ€_10_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_20': safe_float(row.get('ì—°ë ¹ëŒ€_20_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_30': safe_float(row.get('ì—°ë ¹ëŒ€_30_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_40': safe_float(row.get('ì—°ë ¹ëŒ€_40_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_50': safe_float(row.get('ì—°ë ¹ëŒ€_50_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'age_60': safe_float(row.get('ì—°ë ¹ëŒ€_60_ì´ìƒ_ë§¤ì¶œ_ê¸ˆì•¡')) or 0,
        'attractiveness_score': safe_float(row.get('ë§¤ë ¥ë„ì ìˆ˜')),
        'demand_score': safe_float(row.get('ìˆ˜ìš”ì ìˆ˜')),
        'competition_score': safe_float(row.get('ê²½ìŸì ìˆ˜')),
        'cost_score': safe_float(row.get('ë¹„ìš©ì ìˆ˜')),
        'cafe_count': safe_int(row.get('ì¹´í˜_ìˆ˜')),
        'avg_price_per_m2': safe_float(row.get('mÂ²ë‹¹_í‰ê· _ê°€ê²©')) or 0,
    })

# 2) ì €ê°€ ë¸Œëœë“œ ì¹´í˜ ì¢Œí‘œ ë°ì´í„° (ì§€ë„ìš©)
map_points = []
for _, row in df_target.iterrows():
    map_points.append({
        'brand': str(row['ë¸Œëœë“œ']),
        'name': str(row['ì‚¬ì—…ì¥ëª…']),
        'lat': float(row['latitude']),
        'lng': float(row['longitude']),
        'dong_code': str(row['í–‰ì •ë™ì½”ë“œ']),
    })

# 3) ë¸Œëœë“œë³„ í†µê³„
brand_stats = {}
for brand in BRANDS:
    col = f'count_{brand}'
    total_stores = safe_int(df_merged[col].sum()) if col in df_merged.columns else 0

    # í•´ë‹¹ ë¸Œëœë“œê°€ ìˆëŠ” í–‰ì •ë™ì˜ ë§¤ì¶œ í•©ê³„ / ì´ ë§¤ì¥ ìˆ˜ â†’ ì í¬ë‹¹ í‰ê·  ì›”ë§¤ì¶œ
    brand_dongs = df_merged[df_merged[col] > 0] if col in df_merged.columns else pd.DataFrame()
    total_sales_for_brand = brand_dongs['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].sum() if 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡' in brand_dongs.columns else 0
    avg_monthly_sales = int(total_sales_for_brand / total_stores / 1e4) if total_stores > 0 else 0  # ë§Œì› ë‹¨ìœ„

    brand_stats[brand] = {
        'color': BRAND_COLORS[brand],
        'total_stores': total_stores,
        'dong_count': int((df_merged[col] > 0).sum()) if col in df_merged.columns else 0,
        'map_count': int((df_target['ë¸Œëœë“œ'] == brand).sum()),
        'avg_monthly_sales': avg_monthly_sales,  # ì í¬ë‹¹ í‰ê·  ì›”ë§¤ì¶œ (ë§Œì›)
    }


# 4) ì…ì§€ ì¶”ì²œ: ë§¤ë ¥ë„ ì ìˆ˜ ìˆëŠ” ë™ ì¤‘ í•´ë‹¹ ë¸Œëœë“œ ì—†ëŠ” ê³³
recommend_data = []
for d in dong_data:
    if d['attractiveness_score'] is not None:
        for brand in BRANDS:
            if d['brands'].get(brand, 0) == 0:
                recommend_data.append({
                    'dong_name': d['dong_name'],
                    'dong_code': d['dong_code'],
                    'brand': brand,
                    'attractiveness_score': d['attractiveness_score'],
                    'demand_score': d['demand_score'],
                    'competition_score': d['competition_score'],
                    'cost_score': d['cost_score'],
                    'total_workers': d['total_workers'],
                    'monthly_sales': d['monthly_sales'],
                    'cafe_count': d['cafe_count'],
                })

recommend_data.sort(key=lambda x: x['attractiveness_score'], reverse=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON ì €ì¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì¤‘...")

output = {
    'brands': BRANDS,
    'brand_colors': BRAND_COLORS,
    'brand_stats': brand_stats,
    'dong_data': dong_data,
    'map_points': map_points,
    'recommend_top': recommend_data[:200],
}

out_path = os.path.join(OUTPUT_DIR, 'dashboard_data.json')
with open(out_path, 'w', encoding='utf-8') as f:
    json.dump(output, f, ensure_ascii=False, indent=2)

file_size = os.path.getsize(out_path) / 1024 / 1024
print(f"  âœ… dashboard_data.json ì €ì¥ ì™„ë£Œ ({file_size:.1f} MB)")
print(f"     - í–‰ì •ë™ ìˆ˜: {len(dong_data)}")
print(f"     - ì§€ë„ í¬ì¸íŠ¸ ìˆ˜: {len(map_points):,}")
print(f"     - ì…ì§€ ì¶”ì²œ í›„ë³´: {len(recommend_data):,}")
print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
